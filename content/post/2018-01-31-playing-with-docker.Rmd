---
title: Playing With Docker
author: Jonathan Lamberts
date: '2018-02-09'
slug: playing-with-docker
categories:
  - Learning
tags:
  - Docker
  - OpenCV
  - Computer Vision
draft: true
---

# A Little Bit of Background
This semester, I'm taking a course on Computer Vision as part of my Master's degree at Georgia Tech.  The course depends heavily on a specific version of the Python [OpenCV library](https://opencv.org/).  As a conda guy, I tend to run multiple versions of Python and multiple versions of libraries on a single machine, so I first tried creating a new conda environment and running that.

Unfortunately, it turns out that, while OpenCV is available on [Conda Forge](https://anaconda.org/conda-forge/opencv), only the Ubuntu version of the package hosted there works properly with FFmpeg.  This meant that I was unable to read and write video on Windows.  Rather than trying to get the conda version to work on Windows (I'm often on Windows machines) I decided to learn something while I fixed the problem and see if I could make a platform-agnostic version of the environment using Docker.  

Ultimately, I ended up creating two images to use in the class: one image contains the base requirements for running and submitting assignment code, and the other runs a Jupyter notebook to allow for interactive experimentation when working on assignments.  In this post I'll give an overview of what I learned about Docker and what tripped me up, in the hope that it will help someone else in a similar situation.  

# Learning the Docker Basics
When I started, I only had a vague notion that Docker would allow me to keep my library versions consistent across machines and operating systems; I didn't really know anything about the how docker works.  Here's a brief overview.

## Three Major Parts
Beginning with writing the specifications for an environment and ending with a fully functioning container that actually runs code in that environment, the docker workflow has 3 main components.  A **Dockerfile** contains the specifications necessary to build an environment.  An **Image** contains a snapshot of a system that is created using the dockerfile.  A **Container** is a specific instance of an image that actually executes your code or lets you interact with the image's environment (e.g. with a bash shell).

### The Dockerfile: Building the Image
Essentially, a Dockerfile contains a list of commands to run while creating an image and setting up that image's environment.  In my case,  that code installed the required version of the necessary libraries, and set things up so that I could use a jupyter notebook on my host machine while the notebook ran inside of the container.  Let's take a look at the Jupyter image  and break down its parts.

```
FROM jlamberts/omscs-cv-base:spring2018
MAINTAINER Jonathan Lamberts <jonathan.lamberts@gmail.com>

# Install Matplotlib and Jupyter for interaction
RUN conda install -c conda-forge opencv=2.4 matplotlib jupyter

# Expose the notebook port
EXPOSE 8888

RUN mkdir /usr/sandbox/

ENTRYPOINT ["python", "/opt/conda/bin/jupyter-notebook", "--ip=*", "--allow-root"]
CMD ["--notebook-dir=/usr/sandbox"]
```
First off, you'll notice that I'm loading from another image:   `FROM jlamberts/omscs-cv-base:spring2018`  
The `FROM` instruction tells docker to load another image and then execute the rest of the commands on top of that.  Remember that an image is just a snapshot, so this essentially unfreezes the snapshot and installs more stuff on top of it.  One particularly nice feature of Docker is that if you load from an image that you don't have locally, it will check on the [Docker Hub](https://hub.docker.com/), pull it from there, and cache it.  In this case, I'm pulling my base image which already has most of the requirements installed; that base image pulls from ContinuumIO's miniconda image.

Next, the line `RUN conda install -c conda-forge opencv=2.4 matplotlib jupyter` uses conda to install Matplotlib, Jupyter, and OpenCV^[Technically since openCV is already installed on the base image, it doesn't actually install here, but including it in the command along with its version prevents it from upgrading and violating the environment requirements].  In general, the `RUN` instruction simply runs a specified command in a shell (bash by default on Linux).

As you may have gathered from the comment, the `EXPOSE 8888` instruction exposes port 8888, used by the notebook, to the host machine.  Since a docker container runs in a VM, there's no network access between the host machine and the container by default.

Finally, the `ENTRYPOINT` and `CMD` instructions tell the image what to do when it is actually run.  Specifically, `ENTRYPOINT` gives the instructions that are always run^[You can actually override it with `--entrypoint` flag, which I found helpful when debugging] when the image is run.  The `CMD` instruction provides default arguments which are then appended to that entrypoint but are overridden if a user passes additional arguments.  So in this case, the `ENTRYPOINT` runs a jupyter notebook, and the `CMD` sets that notebook to run in the /usr/sandbox directory by default.  If a user instead ran the image with the command `docker run jlamberts/omscs-cv-jupyter --notebook-dir=/usr` the notebook would run in the /usr directory instead.

### The Image: Building The Environment
Now that we have our dockerfile, we can use it to create an image.  When we run the command `docker build -t omscs-cv-jupyter .` in the directory with our dockerfile, Docker will parse the file, pull the necessary dependencies, run the commands in the dockerfile, freeze the final image, and tag it (that's what the `-t` stands for) with the name omscs-cv-jupyter.  After this runs, you can type `docker images` and you'll see that it's included in the list of images available on your machine: 

![images!](/img/docker_images.png)

You might also notice that several other

# Issues and Solutions
I ran into some issues when trying to mount the volume of my local machine to the docker image on windows.  The container would start successfully, but the mounted directory would show up as empty in the container.  The solution ended up being stupidly simple: I just had to share the drive in the docker settings.  
![sharing a drive](/img/docker_share_drive.png)
If you're having a similar issue and this doesn't fix it, I also found a [github issue](https://github.com/docker/for-win/issues/77) reporting that people were able to get it working by unsharing then sharing access to the drive.

# Conclusion
For anyone who's interested in the final results of my experimentation, you can find the repo with the dockerfiles [here](https://github.com/jlamberts/OMSCS-CV-Docker), the base environment image [here](https://hub.docker.com/r/jlamberts/omscs-cv-base/), and the Jupyter environment image [here.](https://hub.docker.com/r/jlamberts/omscs-cv-jupyter/)

# Other Resources
* Docker's [official getting started guide](https://docs.docker.com/get-started/) is a nice, readable intro to Docker
